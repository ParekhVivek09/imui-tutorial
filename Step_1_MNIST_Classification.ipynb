{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.python.framework import graph_util # used for exporting the graph\n",
    "\n",
    "# Importing the MNIST data set.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn as sk\n",
    "import sklearn.metrics\n",
    "\n",
    "MODEL_SAVE_PATH = \"./\"\n",
    "# Please fill in your attendee number for identification of your model later on\n",
    "ATTENDEE_ID = 10\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU and CPU settings\n",
    "If GPU is not available, comment out the bottom block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "GPU_USE = '/gpu:0'\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement=True\n",
    "config.allow_soft_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.1\n",
    "config.gpu_options.allocator_type = 'BFC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"mnist_data/\", one_hot=True) # tf.estimator handles classes itself\n",
    "\n",
    "train_x = mnist.train.images\n",
    "train_y = mnist.train.labels\n",
    "\n",
    "test_x = mnist.test.images\n",
    "test_y = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f925603d978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f925805ba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting an example image\n",
    "i = 1\n",
    "plt.imshow(mnist.train.images[i].reshape(28,28)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, np.argmax(mnist.train.labels[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "n_classes = len(mnist.train.labels[0]) # equals 10 as we have 10 numbers to classify.\n",
    "\n",
    "# Number of features as input for the neural network\n",
    "n_features = len(mnist.train.images[0]) # equals to 768 (28 x 28 image)\n",
    "\n",
    "# Input and output node names\n",
    "input_tensor = \"input\" \n",
    "output_tensor = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Number of neurons per layer\n",
    "n_hidden_1 = 10 \n",
    "\n",
    "# Training settings\n",
    "learning_rate = 0.1\n",
    "batch_size = 100\n",
    "training_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variable definition\n",
    "_x = tf.placeholder(tf.float32, [None, n_features], name=input_tensor)\n",
    "_y = tf.placeholder(tf.float32, [None, n_classes], name=\"y\")\n",
    "\n",
    "rg_weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_features, n_hidden_1])),\n",
    "    'hOut': tf.Variable(tf.random_normal([n_hidden_1, n_classes]))\n",
    "}\n",
    "\n",
    "rg_biases =  {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'bOut': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "    \n",
    "def reg_perceptron(t, weights, biases):\n",
    "    t = tf.nn.relu(tf.add(tf.matmul(t, weights['h1']), biases['b1']), name = \"layer_1\")\n",
    "    t = tf.add(tf.matmul(t, weights['hOut'], name=\"LOut_MatMul\"), biases['bOut'], name = output_tensor)\n",
    "    return t\n",
    "    \n",
    "pred = reg_perceptron(_x, rg_weights, rg_biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Toggle comments to try out different optimizers\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of TF operations\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 - Acc: 0.36, Prec: 0.36,  Rec: 0.36 \n",
      "Epoch:   1 - Acc: 0.53, Prec: 0.53,  Rec: 0.53 \n",
      "Epoch:   2 - Acc: 0.63, Prec: 0.63,  Rec: 0.63 \n",
      "Epoch:   3 - Acc: 0.68, Prec: 0.68,  Rec: 0.68 \n",
      "Epoch:   4 - Acc: 0.73, Prec: 0.73,  Rec: 0.73 \n",
      "Epoch:   5 - Acc: 0.76, Prec: 0.76,  Rec: 0.76 \n",
      "Epoch:   6 - Acc: 0.78, Prec: 0.78,  Rec: 0.78 \n",
      "Epoch:   7 - Acc: 0.80, Prec: 0.80,  Rec: 0.80 \n",
      "Epoch:   8 - Acc: 0.81, Prec: 0.81,  Rec: 0.81 \n",
      "Epoch:   9 - Acc: 0.82, Prec: 0.82,  Rec: 0.82 \n",
      "Epoch:  10 - Acc: 0.83, Prec: 0.83,  Rec: 0.83 \n",
      "Epoch:  11 - Acc: 0.83, Prec: 0.83,  Rec: 0.83 \n",
      "Epoch:  12 - Acc: 0.84, Prec: 0.84,  Rec: 0.84 \n",
      "Epoch:  13 - Acc: 0.84, Prec: 0.84,  Rec: 0.84 \n",
      "Epoch:  14 - Acc: 0.84, Prec: 0.84,  Rec: 0.84 \n",
      "Epoch:  15 - Acc: 0.85, Prec: 0.85,  Rec: 0.85 \n",
      "Epoch:  16 - Acc: 0.85, Prec: 0.85,  Rec: 0.85 \n",
      "Epoch:  17 - Acc: 0.86, Prec: 0.86,  Rec: 0.86 \n",
      "Epoch:  18 - Acc: 0.86, Prec: 0.86,  Rec: 0.86 \n",
      "Epoch:  19 - Acc: 0.87, Prec: 0.87,  Rec: 0.87 \n",
      "Optimization Finished!\n",
      "Final test results: Acc: 0.87, Prec: 0.87,  Rec: 0.87 \n",
      "[[ 947    0    1    2    1    3    7    6   11    2]\n",
      " [   0 1111    5    3    0    1    3    1   10    1]\n",
      " [  24   24  839   37   26    6   26   10   35    5]\n",
      " [  21    1   27  848    4   58    0   15   17   19]\n",
      " [   2    4    6    4  770    3   29    2    6  156]\n",
      " [  35    3    2   31    4  728   16    6   42   25]\n",
      " [  19    3   11    0   26   15  866    2   13    3]\n",
      " [   2   17   26   15   10    4    0  877    4   73]\n",
      " [  10   17   31   42    8   19   24   13  784   26]\n",
      " [  16    5    0    9   48    8    1   26    7  889]]\n",
      "Model save path: ./mnist_model/\n"
     ]
    }
   ],
   "source": [
    "save_path = MODEL_SAVE_PATH + \"mnist_model/\"\n",
    "\n",
    "with tf.device(GPU_USE):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        for epoch in range(training_epochs):\n",
    "            total_batch = int(len(train_x)/batch_size)\n",
    "            \n",
    "            \n",
    "            # Loop over all batches for training\n",
    "            for i in range(total_batch):\n",
    "                lower_bound = i * batch_size\n",
    "                upper_bound = i * batch_size + batch_size\n",
    "                batch_x = train_x[lower_bound : upper_bound]\n",
    "                batch_y = train_y[lower_bound : upper_bound]\n",
    "\n",
    "                # Run optimization operation and calculate cost\n",
    "                feed_dict = {_x: batch_x, _y: batch_y}\n",
    "                _, c = sess.run([optimizer, cost], feed_dict = feed_dict)\n",
    "                \n",
    "            \n",
    "            # Print test results.\n",
    "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(_y, 1))\n",
    "            acc_op = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            accuracy = acc_op.eval({_x: test_x, _y: test_y})\n",
    "\n",
    "            y_pred = tf.argmax(pred, 1).eval({_x: test_x, _y: test_y})\n",
    "            y_true = np.argmax(test_y,1)\n",
    "            precision = sk.metrics.precision_score(y_true, y_pred, average=\"micro\")\n",
    "            recall = sk.metrics.recall_score(y_true, y_pred, average=\"micro\")\n",
    "            print (\"Epoch: %3.i - Acc: %.2f, Prec: %.2f,  Rec: %.2f \" % (epoch, accuracy, precision, recall))\n",
    "\n",
    "#             op_assign_cost = _cost.assign(avg_cost)\n",
    "#             op_assign_acc = _accuracy.assign(accuracy)\n",
    "#             _, _ = sess.run([op_assign_cost, op_assign_acc]) \n",
    "\n",
    "#             feed_dict = {_x: test_x, _y: test_y}\n",
    "#             summary = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "#             train_writer.add_summary(summary,  _epoch_count.eval())\n",
    "\n",
    "            saver.save(sess, save_path + \"model\", global_step=epoch, write_meta_graph=True)\n",
    "            \n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(_y, 1))\n",
    "        acc_op = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        accuracy = acc_op.eval({_x: test_x, _y: test_y})\n",
    "\n",
    "        y_pred = tf.argmax(pred, 1).eval({_x: test_x, _y: test_y})\n",
    "        y_true = np.argmax(test_y,1)\n",
    "        precision = sk.metrics.precision_score(y_true, y_pred, average=\"micro\")\n",
    "        recall = sk.metrics.recall_score(y_true, y_pred, average=\"micro\")\n",
    "        print (\"Final test results: Acc: %.2f, Prec: %.2f,  Rec: %.2f \" % (accuracy, precision, recall))\n",
    "        \n",
    "        print (sk.metrics.confusion_matrix(y_true, y_pred))\n",
    "        \n",
    "        print(\"Model save path:\", save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and exporting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def freeze_graph(model_folder, model_file_name = None):\n",
    "    GPU_USE = '/cpu:0'\n",
    "    config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "    \n",
    "    # We retrieve our checkpoint fullpath\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    print (absolute_model_folder)\n",
    "    if (model_file_name == None):\n",
    "        model_file_name = input_checkpoint.split(\"/\")[-1].split(\".\")[0]\n",
    "    else:\n",
    "        input_checkpoint = absolute_model_folder + \"/\" + model_file_name\n",
    "    print (model_file_name)\n",
    "    if ATTENDEE_ID == None:\n",
    "        print (\"ERROR: Please set ATTENDEE_ID first\")\n",
    "        return\n",
    "    \n",
    "    # If you use our Script outside of the tutorial please specify your path to store the model\n",
    "    output_graph = \"/var/www/html/tutorial-data/model-\" + str(ATTENDEE_ID) + \".pb\"\n",
    "\n",
    "    # Output node for TensorFlow to decide which part of the Graph to keep.\n",
    "\n",
    "    print(\"Saver is loading: \" + input_checkpoint + '.meta')\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=True)\n",
    "\n",
    "    # We retrieve the protobuf graph definition\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "\n",
    "    # start session and write the exported file. \n",
    "    with tf.device(GPU_USE):\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, input_checkpoint)\n",
    "\n",
    "            output_graph_def = graph_util.convert_variables_to_constants(\n",
    "                sess, # The session is used to retrieve the weights\n",
    "                input_graph_def, # The graph_def is used to retrieve the nodes \n",
    "                [output_tensor] # The output node names are used to select the useful nodes.\n",
    "            ) \n",
    "\n",
    "            # Serialize and dump the output graph to the filesystem\n",
    "            with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "                f.write(output_graph_def.SerializeToString())\n",
    "            print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
    "            print(\"Wrote model to %s\" % output_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mnist_model\n",
      "model-19\n",
      "Saver is loading: ./mnist_model/model-19.meta\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_model/model-19\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n",
      "14 ops in the final graph.\n",
      "Wrote model to /var/www/html/tutorial-data/model-1.pb\n"
     ]
    }
   ],
   "source": [
    "freeze_graph(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
